name: Performance Benchmark

on:
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      devices:
        description: 'Devices to benchmark (comma-separated: CPU,GPU,NPU)'
        required: false
        default: 'CPU,GPU,NPU'
        type: string
      iterations:
        description: 'Number of iterations per device'
        required: false
        default: '3'
        type: number
      model_name:
        description: 'Model to use for benchmarking'
        required: false
        default: 'FluidInference/qwen3-0.6b-int4-ov-npu'
        type: string
      compare_with_baseline:
        description: 'Compare with baseline performance'
        required: false
        default: true
        type: boolean

env:
  OPENVINO_VERSION: "2025.2.0.0"

jobs:
  benchmark:
    name: Performance Benchmark
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest]
        include:
          - os: ubuntu-latest
            runtime: linux-x64
          - os: windows-latest
            runtime: win-x64

    steps:
    - uses: actions/checkout@v4

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: '8.0.x'

    - name: Cache NuGet packages
      uses: actions/cache@v4
      with:
        path: ~/.nuget/packages
        key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
        restore-keys: |
          ${{ runner.os }}-nuget-

    - name: Cache Model
      uses: actions/cache@v4
      with:
        path: ./Models
        key: model-${{ inputs.model_name || 'FluidInference/qwen3-0.6b-int4-ov-npu' }}-v1
        restore-keys: |
          model-${{ inputs.model_name || 'FluidInference/qwen3-0.6b-int4-ov-npu' }}-

    - name: Cache Baseline Performance Data
      if: inputs.compare_with_baseline
      uses: actions/cache@v4
      with:
        path: ./baseline-performance
        key: baseline-performance-${{ matrix.runtime }}-v1
        restore-keys: |
          baseline-performance-${{ matrix.runtime }}-

    - name: Restore dependencies
      run: dotnet restore OpenVINO.NET.sln

    - name: Cache OpenVINO Runtime (Windows)
      if: matrix.os == 'windows-latest'
      id: cache-openvino-windows
      uses: actions/cache@v4
      with:
        path: build/native/openvino_genai_windows_${{ env.OPENVINO_VERSION }}_x86_64
        key: openvino-runtime-windows-${{ env.OPENVINO_VERSION }}

    - name: Download OpenVINO Runtime (Windows)
      if: matrix.os == 'windows-latest' && steps.cache-openvino-windows.outputs.cache-hit != 'true'
      shell: pwsh
      run: |
        Write-Host "Downloading OpenVINO GenAI Runtime for Windows..."
        $outputPath = "build/native"
        New-Item -ItemType Directory -Force -Path $outputPath
        $urls = @(
          "https://storage.openvinotoolkit.org/repositories/openvino_genai/packages/2025.2/windows/openvino_genai_windows_${{ env.OPENVINO_VERSION }}_x86_64.zip",
          "https://storage.openvinotoolkit.org/repositories/openvino_genai/packages/2025.2/windows/openvino_genai_runtime_windows_${{ env.OPENVINO_VERSION }}_x86_64.zip"
        )
        $downloaded = $false
        $output = "openvino_genai_runtime.zip"
        foreach ($url in $urls) {
          Write-Host "Trying: $url"
          try {
            Invoke-WebRequest -Uri $url -OutFile $output -UserAgent "OpenVINO.NET/1.0"
            if ((Get-Item $output).Length -gt 1MB) {
              Write-Host "Successfully downloaded from $url"
              $downloaded = $true
              break
            } else {
              Write-Host "Downloaded file is too small, trying next URL..."
              Remove-Item $output
            }
          } catch {
            Write-Host "Failed to download from $url, trying next URL..."
          }
        }
        if (-not $downloaded) {
          Write-Host "Failed to download OpenVINO runtime from any URL."
          exit 1
        }
        Expand-Archive -Path $output -DestinationPath $outputPath -Force
        Remove-Item $output
        Write-Host "OpenVINO Runtime downloaded successfully"

    - name: Setup OpenVINO DLLs (Windows)
      if: matrix.os == 'windows-latest'
      shell: pwsh
      run: |
        $runtimePath = "build/native/openvino_genai_windows_${{ env.OPENVINO_VERSION }}_x86_64/runtime"
        $targetPath = "build/native/runtimes/win-x64/native"
        New-Item -ItemType Directory -Force -Path $targetPath
        Copy-Item "$runtimePath/bin/intel64/Release/*.dll" -Destination $targetPath -Force
        Copy-Item "$runtimePath/3rdparty/tbb/bin/*.dll" -Destination $targetPath -Force
        Write-Host "Copied $(Get-ChildItem $targetPath -Filter *.dll | Measure-Object).Count DLL files"

    - name: Download OpenVINO Runtime (Linux)
      if: matrix.os == 'ubuntu-latest'
      id: cache-openvino-linux
      uses: actions/cache@v4
      with:
        path: build/native/runtimes/linux-x64/native
        key: openvino-runtime-linux-${{ env.OPENVINO_VERSION }}

    - name: Download OpenVINO Runtime (Linux)
      if: matrix.os == 'ubuntu-latest' && steps.cache-openvino-linux.outputs.cache-hit != 'true'
      run: |
        echo "Downloading OpenVINO GenAI Runtime for Linux..."
        outputPath="build/native"
        mkdir -p $outputPath
        urls=(
          "https://storage.openvinotoolkit.org/repositories/openvino_genai/packages/2025.2/linux/openvino_genai_ubuntu24_${{ env.OPENVINO_VERSION }}_x86_64.tar.gz"
          "https://storage.openvinotoolkit.org/repositories/openvino_genai/packages/2025.2/linux/openvino_genai_ubuntu22_${{ env.OPENVINO_VERSION }}_x86_64.tar.gz"
          "https://storage.openvinotoolkit.org/repositories/openvino_genai/packages/2025.2/linux/openvino_genai_ubuntu20_${{ env.OPENVINO_VERSION }}_x86_64.tar.gz"
          "https://storage.openvinotoolkit.org/repositories/openvino_genai/packages/2025.2/linux/openvino_genai_runtime_ubuntu24_${{ env.OPENVINO_VERSION }}_x86_64.tar.gz"
        )
        downloaded=false
        for url in "${urls[@]}"; do
          echo "Trying: $url"
          if wget -q --user-agent="OpenVINO.NET/1.0" -O openvino_genai_runtime.tar.gz "$url"; then
            if file openvino_genai_runtime.tar.gz | grep -q "gzip compressed"; then
              echo "âœ“ Successfully downloaded from: $url"
              downloaded=true
              break
            else
              echo "âœ— Invalid file format from: $url"
              rm -f openvino_genai_runtime.tar.gz
            fi
          else
            echo "âœ— Failed to download from: $url"
          fi
        done
        if [ "$downloaded" = false ]; then
          echo "âŒ Failed to download OpenVINO runtime from any URL"
          exit 1
        fi
        
        echo "Extracting runtime..."
        tar -xzf openvino_genai_runtime.tar.gz
        
        # Find the extracted directory (handle different naming conventions)
        extracted_dir=""
        for dir in openvino_genai_*; do
          if [ -d "$dir" ]; then
            extracted_dir="$dir"
            break
          fi
        done
        
        if [ -z "$extracted_dir" ]; then
          echo "âŒ Could not find extracted OpenVINO directory"
          ls -la
          exit 1
        fi
        
        echo "Found extracted directory: $extracted_dir"
        
        # Create target directory and copy files preserving symlinks
        mkdir -p build/native/runtimes/linux-x64/native
        
        # Try different potential library paths
        if [ -d "$extracted_dir/runtime/lib/intel64" ]; then
          cp -a "$extracted_dir/runtime/lib/intel64/"* build/native/runtimes/linux-x64/native/
        elif [ -d "$extracted_dir/lib" ]; then
          cp -a "$extracted_dir/lib/"* build/native/runtimes/linux-x64/native/
        else
          echo "âŒ Could not find library directory in $extracted_dir"
          ls -la "$extracted_dir"
          exit 1
        fi
        
        rm -rf openvino_genai_runtime.tar.gz "$extracted_dir"
        echo "âœ“ OpenVINO runtime setup completed"

    - name: Build solution
      run: dotnet build OpenVINO.NET.sln --configuration Release

    - name: Download Benchmark Model
      working-directory: ./samples/QuickDemo
      run: |
        mkdir -p Models
        cd Models
        
        # Use model name from input or default
        MODEL_NAME="${{ inputs.model_name || 'FluidInference/qwen3-0.6b-int4-ov-npu' }}"
        MODEL_DIR=$(echo "$MODEL_NAME" | cut -d'/' -f2)
        
        if [ ! -d "$MODEL_DIR" ] || [ ! -f "$MODEL_DIR/openvino_model.xml" ]; then
          echo "Downloading model: $MODEL_NAME"
          
          mkdir -p "$MODEL_DIR"
          cd "$MODEL_DIR"
          
          # Download key files
          for file in openvino_model.xml openvino_model.bin openvino_tokenizer.xml openvino_tokenizer.bin openvino_detokenizer.xml openvino_detokenizer.bin config.json generation_config.json; do
            echo "Downloading $file..."
            curl -L -f -o "$file" "https://huggingface.co/$MODEL_NAME/resolve/main/$file" --user-agent "OpenVINO.NET/1.0" || echo "Warning: Failed to download $file (may be optional)"
          done
          
          cd ..
          echo "âœ“ Model download completed"
        else
          echo "âœ“ Model already cached"
        fi
      shell: bash

    - name: Set Model Path Environment
      run: |
        MODEL_NAME="${{ inputs.model_name || 'FluidInference/qwen3-0.6b-int4-ov-npu' }}"
        MODEL_DIR=$(echo "$MODEL_NAME" | cut -d'/' -f2)
        MODEL_PATH="$(pwd)/samples/QuickDemo/Models/$MODEL_DIR"
        echo "QUICKDEMO_MODEL_PATH=$MODEL_PATH" >> $GITHUB_ENV
      shell: bash

    - name: Setup Memory Monitoring (Linux)
      if: matrix.os == 'ubuntu-latest'
      run: |
        # Install system monitoring tools
        sudo apt-get update
        sudo apt-get install -y htop sysstat
        echo "âœ“ Memory monitoring tools installed"

    - name: Run Performance Benchmark
      working-directory: ./samples/QuickDemo
      shell: pwsh
      run: |
        $devices = "${{ inputs.devices || 'CPU,GPU,NPU' }}" -split ','
        $iterations = [int]"${{ inputs.iterations || 3 }}"
        $timestamp = Get-Date -Format "yyyyMMdd-HHmmss"
        $benchmarkResults = @()
        
        Write-Host "Performance Benchmark - $timestamp"
        Write-Host "Devices: $($devices -join ', ')"
        Write-Host "Iterations per device: $iterations"
        Write-Host "Platform: ${{ matrix.runtime }}"
        Write-Host ""
        
        foreach ($device in $devices) {
          $device = $device.Trim()
          Write-Host "Benchmarking device: $device"
          Write-Host "================================"
          
          $deviceResults = @{
            Device = $device
            Platform = "${{ matrix.runtime }}"
            Timestamp = $timestamp
            Iterations = @()
            Success = $false
            ErrorMessage = ""
          }
          
          for ($i = 1; $i -le $iterations; $i++) {
            Write-Host "Iteration $i/$iterations..."
            
            try {
              # Start memory monitoring in background
              if ("${{ matrix.os }}" -eq "ubuntu-latest") {
                Start-Process -FilePath "bash" -ArgumentList @("-c", "while sleep 1; do echo `$(date): `$(free -m | grep '^Mem:' | awk '{print `$3}') MB; done > memory-$device-$i.log") -NoNewWindow
                $memPid = $LASTEXITCODE
              }
              
              $startTime = Get-Date
              $output = dotnet run --configuration Release -- --device $device 2>&1
              $endTime = Get-Date
              $exitCode = $LASTEXITCODE
              
              # Stop memory monitoring
              if ("${{ matrix.os }}" -eq "ubuntu-latest" -and $memPid) {
                Stop-Process -Id $memPid -ErrorAction SilentlyContinue
              }
              
              if ($exitCode -eq 0) {
                # Parse performance metrics
                $tpsMatch = [regex]::Match($output, 'Performance:\s+(\d+\.\d+)\s+tokens/sec')
                $latencyMatch = [regex]::Match($output, 'First token:\s+(\d+)ms')
                
                $iterationResult = @{
                  Iteration = $i
                  Success = $true
                  TokensPerSecond = if ($tpsMatch.Success) { [double]$tpsMatch.Groups[1].Value } else { 0 }
                  FirstTokenLatencyMs = if ($latencyMatch.Success) { [int]$latencyMatch.Groups[1].Value } else { 0 }
                  TotalTimeMs = ($endTime - $startTime).TotalMilliseconds
                  MemoryUsageMB = 0  # Will be updated from memory log if available
                }
                
                # Parse memory usage if available
                if ("${{ matrix.os }}" -eq "ubuntu-latest" -and (Test-Path "memory-$device-$i.log")) {
                  $memData = Get-Content "memory-$device-$i.log" | ForEach-Object { 
                    if ($_ -match ': (\d+) MB') { [int]$matches[1] } 
                  }
                  if ($memData) {
                    $iterationResult.MemoryUsageMB = ($memData | Measure-Object -Maximum).Maximum
                  }
                  Remove-Item "memory-$device-$i.log" -ErrorAction SilentlyContinue
                }
                
                $deviceResults.Iterations += $iterationResult
                $deviceResults.Success = $true
                
                Write-Host "  âœ“ TPS: $($iterationResult.TokensPerSecond), Latency: $($iterationResult.FirstTokenLatencyMs)ms, Memory: $($iterationResult.MemoryUsageMB)MB"
              } else {
                Write-Host "  âœ— Failed with exit code: $exitCode"
                $deviceResults.ErrorMessage = "Exit code: $exitCode, Output: $output"
                break
              }
            } catch {
              Write-Host "  âœ— Exception: $($_.Exception.Message)"
              $deviceResults.ErrorMessage = $_.Exception.Message
              break
            }
          }
          
          # Calculate averages for successful runs
          if ($deviceResults.Success -and $deviceResults.Iterations.Count -gt 0) {
            $successfulIterations = $deviceResults.Iterations | Where-Object { $_.Success }
            
            $deviceResults.AverageTokensPerSecond = ($successfulIterations | Measure-Object -Property TokensPerSecond -Average).Average
            $deviceResults.AverageFirstTokenLatencyMs = ($successfulIterations | Measure-Object -Property FirstTokenLatencyMs -Average).Average
            $deviceResults.AverageTotalTimeMs = ($successfulIterations | Measure-Object -Property TotalTimeMs -Average).Average
            $deviceResults.MaxMemoryUsageMB = ($successfulIterations | Measure-Object -Property MemoryUsageMB -Maximum).Maximum
            
            Write-Host "  Average TPS: $($deviceResults.AverageTokensPerSecond.ToString('F2'))"
            Write-Host "  Average Latency: $($deviceResults.AverageFirstTokenLatencyMs.ToString('F0'))ms"
            Write-Host "  Max Memory: $($deviceResults.MaxMemoryUsageMB)MB"
          }
          
          $benchmarkResults += $deviceResults
          Write-Host ""
        }
        
        # Save detailed results to JSON
        $resultFile = "benchmark-results-${{ matrix.runtime }}-$timestamp.json"
        $benchmarkResults | ConvertTo-Json -Depth 10 | Out-File -FilePath $resultFile
        
        # Create summary table
        $summaryFile = "benchmark-summary-${{ matrix.runtime }}-$timestamp.txt"
        "Performance Benchmark Summary - ${{ matrix.runtime }}" | Out-File -FilePath $summaryFile
        "Generated: $timestamp" | Out-File -FilePath $summaryFile -Append
        "" | Out-File -FilePath $summaryFile -Append
        "Device       | Status | Avg TPS | Avg Latency | Max Memory | Iterations" | Out-File -FilePath $summaryFile -Append
        "------------ | ------ | ------- | ----------- | ---------- | ----------" | Out-File -FilePath $summaryFile -Append
        
        foreach ($result in $benchmarkResults) {
          $status = if ($result.Success) { "âœ“" } else { "âœ—" }
          $avgTps = if ($result.Success) { $result.AverageTokensPerSecond.ToString("F1") } else { "N/A" }
          $avgLatency = if ($result.Success) { $result.AverageFirstTokenLatencyMs.ToString("F0") + "ms" } else { "N/A" }
          $maxMemory = if ($result.Success -and $result.MaxMemoryUsageMB -gt 0) { $result.MaxMemoryUsageMB.ToString() + "MB" } else { "N/A" }
          $iterCount = if ($result.Success) { $result.Iterations.Count } else { "0" }
          
          "$($result.Device.PadRight(12)) | $($status.PadRight(6)) | $($avgTps.PadRight(7)) | $($avgLatency.PadRight(11)) | $($maxMemory.PadRight(10)) | $iterCount" | Out-File -FilePath $summaryFile -Append
        }
        
        "" | Out-File -FilePath $summaryFile -Append
        
        # Add error details for failed devices
        $failedDevices = $benchmarkResults | Where-Object { -not $_.Success }
        if ($failedDevices) {
          "Failed Devices:" | Out-File -FilePath $summaryFile -Append
          foreach ($failed in $failedDevices) {
            "â€¢ $($failed.Device): $($failed.ErrorMessage)" | Out-File -FilePath $summaryFile -Append
          }
        }
        
        Write-Host "Benchmark Results Summary:"
        Get-Content $summaryFile
        
        # Set environment variables for comparison step
        $bestDevice = $benchmarkResults | Where-Object { $_.Success } | Sort-Object -Property AverageTokensPerSecond -Descending | Select-Object -First 1
        if ($bestDevice) {
          "BEST_DEVICE=$($bestDevice.Device)" | Out-File -FilePath $env:GITHUB_ENV -Append
          "BEST_TPS=$($bestDevice.AverageTokensPerSecond.ToString('F2'))" | Out-File -FilePath $env:GITHUB_ENV -Append
        }

    - name: Compare with Baseline
      if: inputs.compare_with_baseline
      shell: pwsh
      run: |
        $baselineDir = "baseline-performance"
        $currentResults = "benchmark-results-${{ matrix.runtime }}-*.json"
        
        if (-not (Test-Path $baselineDir)) {
          New-Item -ItemType Directory -Path $baselineDir -Force
          Write-Host "No baseline data found. Current results will be used as baseline."
          Copy-Item $currentResults $baselineDir/
        } else {
          Write-Host "Comparing with baseline performance..."
          
          # Load current and baseline results
          $currentFile = Get-ChildItem $currentResults | Sort-Object LastWriteTime -Descending | Select-Object -First 1
          $baselineFile = Get-ChildItem "$baselineDir/benchmark-results-${{ matrix.runtime }}-*.json" | Sort-Object LastWriteTime -Descending | Select-Object -First 1
          
          if ($currentFile -and $baselineFile) {
            $current = Get-Content $currentFile.FullName | ConvertFrom-Json
            $baseline = Get-Content $baselineFile.FullName | ConvertFrom-Json
            
            Write-Host "Performance Comparison vs Baseline:"
            Write-Host "===================================="
            
            foreach ($currentDevice in $current) {
              if ($currentDevice.Success) {
                $baselineDevice = $baseline | Where-Object { $_.Device -eq $currentDevice.Device -and $_.Success }
                
                if ($baselineDevice) {
                  $tpsChange = (($currentDevice.AverageTokensPerSecond - $baselineDevice.AverageTokensPerSecond) / $baselineDevice.AverageTokensPerSecond) * 100
                  $latencyChange = (($currentDevice.AverageFirstTokenLatencyMs - $baselineDevice.AverageFirstTokenLatencyMs) / $baselineDevice.AverageFirstTokenLatencyMs) * 100
                  
                  $tpsSymbol = if ($tpsChange -gt 5) { "ðŸ“ˆ" } elseif ($tpsChange -lt -5) { "ðŸ“‰" } else { "âž¡ï¸" }
                  $latencySymbol = if ($latencyChange -lt -5) { "ðŸ“ˆ" } elseif ($latencyChange -gt 5) { "ðŸ“‰" } else { "âž¡ï¸" }
                  
                  Write-Host "$($currentDevice.Device):"
                  Write-Host "  TPS: $($baselineDevice.AverageTokensPerSecond.ToString('F1')) â†’ $($currentDevice.AverageTokensPerSecond.ToString('F1')) ($($tpsChange.ToString('F1'))%) $tpsSymbol"
                  Write-Host "  Latency: $($baselineDevice.AverageFirstTokenLatencyMs.ToString('F0'))ms â†’ $($currentDevice.AverageFirstTokenLatencyMs.ToString('F0'))ms ($($latencyChange.ToString('F1'))%) $latencySymbol"
                } else {
                  Write-Host "$($currentDevice.Device): No baseline data available"
                }
              }
            }
            
            # Update baseline if current performance is significantly better
            $shouldUpdateBaseline = $false
            foreach ($currentDevice in $current) {
              if ($currentDevice.Success) {
                $baselineDevice = $baseline | Where-Object { $_.Device -eq $currentDevice.Device -and $_.Success }
                if ($baselineDevice -and $currentDevice.AverageTokensPerSecond -gt ($baselineDevice.AverageTokensPerSecond * 1.05)) {
                  $shouldUpdateBaseline = $true
                  break
                }
              }
            }
            
            if ($shouldUpdateBaseline) {
              Write-Host ""
              Write-Host "ðŸ“Š Performance improvement detected. Updating baseline..."
              Copy-Item $currentFile.FullName $baselineDir/
            }
          }
        }

    - name: Upload Benchmark Results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results-${{ matrix.runtime }}
        path: |
          ./samples/QuickDemo/benchmark-results-*.json
          ./samples/QuickDemo/benchmark-summary-*.txt

    - name: Create Performance Summary
      shell: pwsh
      run: |
        $summaryFile = Get-ChildItem "./samples/QuickDemo/benchmark-summary-${{ matrix.runtime }}-*.txt" | Sort-Object LastWriteTime -Descending | Select-Object -First 1
        
        if ($summaryFile) {
          Write-Host "## Performance Benchmark Results (${{ matrix.runtime }})" > performance-summary.md
          Write-Host "" >> performance-summary.md
          Write-Host "**Best Device:** $env:BEST_DEVICE ($env:BEST_TPS TPS)" >> performance-summary.md
          Write-Host "" >> performance-summary.md
          Write-Host "### Detailed Results" >> performance-summary.md
          Write-Host "``````" >> performance-summary.md
          Get-Content $summaryFile.FullName >> performance-summary.md
          Write-Host "``````" >> performance-summary.md
          
          Write-Host ""
          Get-Content performance-summary.md
        }

    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          if (fs.existsSync('performance-summary.md')) {
            const summary = fs.readFileSync('performance-summary.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });
          }
